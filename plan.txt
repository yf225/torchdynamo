# Keep this branch in sync with https://github.com/jansel/torchdynamo/ "inductor" branch.

-------

### Instructions ###

export PATH="/opt/slurm/bin:$PATH"

# Use one of following to allocate GPU node
srun --nodes=1 --gpus-per-node=8 -p dev -t 72:00:00 --exclusive --pty /bin/bash -l
srun --nodes=1 --gpus-per-node=8 -p train -t 72:00:00 --exclusive --pty /bin/bash -l
srun --nodes=1 --gpus-per-node=8 -p scavenge -t 72:00:00 --exclusive --pty /bin/bash -l

conda create -n torch_nightly_cuda python=3.8
conda activate torch_nightly_cuda
export MODULEPATH=/data/shared/modulefiles:$MODULEPATH
module unload cuda
module unload nccl
module unload nccl_efa
module load cuda/11.4 nccl/2.12.7-cuda.11.4 nccl_efa/1.2.0-nccl.2.12.7-cuda.11.4
source /data/shared/bin/cluster_env_new.sh
export CUDA_HOME=/usr/local/cuda-11.4
export NCCL_INCLUDE_DIR=/usr/local/cuda-11.4/include
export CUDA_INSTALL_PATH=/usr/local/cuda-11.4
export CUDACXX=${CUDA_INSTALL_PATH}/bin/nvcc
export PYTHONPATH=/fsx/users/${USER}/cutlass/tools/library/scripts:$PYTHONPATH

# Step 1: Set up conda environment
# pip3 install --pre torch torchtext torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cu113
#
# Step 2: Install torchdynamo
# cd /fsx/users/${USER}
# git clone https://github.com/yf225/torchdynamo -b inductor
# cd /fsx/users/${USER}/torchdynamo_yf225
# pip install -r requirements.txt
# python setup.py develop
#
# Step 3: Set up torchbench
# cd /fsx/users/${USER}
# git clone https://github.com/fairinternal/torchbench
# cd /fsx/users/${USER}/torchbench
# python install.py
#
# Step 4: Install triton
# cd /fsx/users/${USER}
# git clone https://github.com/openai/triton.git
# cd triton/python
# pip install cmake
# pip install -e .
#
# Step 5: Install tensorrt and torch_tensorrt (for inference experiments)
# pip install --upgrade setuptools pip
# pip install nvidia-pyindex
# pip install --upgrade nvidia-tensorrt
# cd /fsx/users/${USER}
# git clone https://github.com/pytorch/TensorRT
# cd /fsx/users/${USER}/TensorRT
# cd py && python3 setup.py install --fx-only

cd /fsx/users/${USER}/torchdynamo_yf225

# Training
./benchmarks/torchbench.py -dcuda --inductor-settings --float32 -n50 --inductor --training  # TorchInductor + Triton
./benchmarks/torchbench.py -dcuda --inductor-settings --float32 -n50 --backend=cudagraphs_ts --nvfuser --training  # NVFuser

# Inference
./benchmarks/torchbench.py -dcuda --inductor-settings --float16 -n50 --inductor  # TorchInductor + Triton
./benchmarks/torchbench.py -dcuda --inductor-settings --float16 -n50 --backend=cudagraphs_ts --nvfuser  # NVFuser
./benchmarks/torchbench.py -dcuda --inductor-settings --float16 -n50 --speedup-trt  # TensorRT (no TorchDynamo)
./benchmarks/torchbench.py -dcuda --inductor-settings --float16 -n50 --speedup-fx2trt-fp16  # FX to TensorRT (use TorchDynamo)