# Keep this branch in sync with https://github.com/jansel/torchdynamo/ "inductor" branch.

-------

### Instructions:

export PATH="/opt/slurm/bin:$PATH"

srun --nodes=1 --gpus-per-node=8 -p dev -t 72:00:00 --exclusive --pty /bin/bash -l
srun --nodes=4 --gpus-per-node=8 -p train -t 72:00:00 --exclusive --pty /bin/bash -l
srun --nodes=8 --gpus-per-node=8 -p scavenge -t 72:00:00 --exclusive --pty /bin/bash -l

conda deactivate && conda deactivate && conda deactivate
. /fsx/users/willfeng/conda/etc/profile.d/conda.sh
export PATH="/fsx/users/willfeng/conda/bin:$PATH"
conda deactivate && conda deactivate && conda deactivate
conda activate torch_nightly_cuda
export MODULEPATH=/data/shared/modulefiles:$MODULEPATH
module unload cuda
module unload nccl
module unload nccl_efa
module load cuda/11.4 nccl/2.12.7-cuda.11.4 nccl_efa/1.2.0-nccl.2.12.7-cuda.11.4
source /data/shared/bin/cluster_env_new.sh
source /data/home/willfeng/setup_efa.sh
export CUDA_HOME=/usr/local/cuda-11.4
export NCCL_INCLUDE_DIR=/usr/local/cuda-11.4/include

# First time only, no need to do this if you are using torch_nightly_cuda from /fsx/users/willfeng/conda/
#
# Step 1: Set up conda environment
# pip3 install --pre torch torchtext torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cu113
#
# Step 2: Install torchdynamo
# cd /fsx/users/${USER}
# git clone https://github.com/yf225/torchdynamo -b inductor
# cd /fsx/users/${USER}/torchdynamo_yf225
# pip install -r requirements.txt
# python setup.py develop
#
# Step 3: Set up torchbench
# cd /fsx/users/${USER}
# git clone https://github.com/fairinternal/torchbench
# cd /fsx/users/${USER}/torchbench
# python install.py
#
# Step 4: Install triton
# git clone https://github.com/openai/triton.git
# cd triton/python
# pip install cmake
# pip install -e .

cd /fsx/users/${USER}/torchdynamo_yf225

# Training
./benchmarks/torchbench.py -dcuda --inductor-settings --float32 -n50 --inductor --training  # TorchInductor + Triton
./benchmarks/torchbench.py -dcuda --inductor-settings --float32 -n50 --backend=cudagraphs_ts --nvfuser --training  # NVFuser

# Inference
./benchmarks/torchbench.py -dcuda --inductor-settings --float16 -n50 --inductor  # TorchInductor + Triton
./benchmarks/torchbench.py -dcuda --inductor-settings --float16 -n50 --backend=cudagraphs_ts --nvfuser  # NVFuser
