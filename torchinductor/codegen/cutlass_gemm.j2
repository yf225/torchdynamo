# import jinja2
# generated_kernel = jinja2.Template("""
# # ... The generated GEMM epilogue fusion kernel ...
# # ... 
# {% if pointwise_code %}
# {{ pointwise_code | indent(4, true) }}
# {% endif %}
# # ...
# """)

import torch
from torchinductor.compile_fx import stream

# System modules
import numpy as np
import os
import os.path
import sys
import ctypes
from types import SimpleNamespace

# CUDA Python modules
from cuda import cuda
from cuda import nvrtc

# CUTLASS modules
import library
import manifest as cutlass_manifest
import generator
import rt

username = os.environ.get('USER')

gemm = None

# TODO(yf225): add autotuning and kernel selection

def compile_cuda_module():
    global gemm

    cuda_ver = "11.4"
    cuda_arch = "80"  # assuming A100

    # Construct an SGEMM
    manifest = cutlass_manifest.Manifest()
    generator.GenerateSM50_Simt(manifest, cuda_ver)

    # Look up the GEMM operation
    operation = manifest.operations_by_name['cutlass_simt_sgemm_128x128_8x2_nn_align1']

    # Construct a runtime GEMM operation
    gemm = rt.Gemm(operation)

    # Construct a module
    architectures = [80,]
    include_paths = [
      f'/fsx/users/{username}/cutlass/include',
      f'/fsx/users/{username}/cutlass/tools/util/include',
      f'/usr/local/cuda-{cuda_ver}/include',
      f'/usr/local/cuda-{cuda_ver}/targets/x86_64-linux/include',
    ]

    compilation_options = rt.CompilationOptions(architectures, include_paths)
    # NOTE: compilation needs to happen outside of CUDA stream capture (e.g. when capturing for CUDA graph)
    module = rt.Module('module.cu', [gemm], compilation_options)


# # TODO(yf225): Can we use TorchDynamo / TorchInductor caching mechanism to reuse kernel for subsequent runs?
# @cached
def {{kernel_name}}(
    tensor_A_torch,
    tensor_B_torch,
    tensor_D_torch,
    M,
    N,
    K,
):
    global gemm
    global stream

    # Formula: D = alpha * (A @ B) + beta * C
    # TODO(yf225): for some weird reason, no matter what bias tensor we pass into the following GEMM operation, it will not be used. We need to debug this.
    tensor_C_torch = torch.empty(M, N, device='cuda', dtype=tensor_A_torch.dtype)

    arguments = rt.GemmArguments()
    arguments.problem_size = rt.GemmCoord(M, N, K)
    arguments.A = rt.TensorRef(tensor_A_torch.data_ptr(), tensor_A_torch.stride()[0])
    arguments.B = rt.TensorRef(tensor_B_torch.data_ptr(), tensor_B_torch.stride()[0])
    arguments.C = rt.TensorRef(tensor_C_torch.data_ptr(), tensor_C_torch.stride()[0])
    arguments.D = rt.TensorRef(tensor_D_torch.data_ptr(), tensor_D_torch.stride()[0])

    host_workspace = bytearray(gemm.get_host_workspace_size(arguments))
    device_workspace = None

    launch_config = gemm.plan(arguments)
    byte_count = gemm.initialize(host_workspace, device_workspace, launch_config, arguments, stream=stream)
    err = gemm.run(host_workspace, device_workspace, launch_config, stream=stream)
    if err != cuda.CUresult.CUDA_SUCCESS:
      raise RuntimeError('CUDA Error %s' % str(err))
    torch.cuda.synchronize()


# TODO(yf225): emit this in global `if __name__ == "__main__":` block?
compile_cuda_module()